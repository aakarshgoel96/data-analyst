{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with MongoDB\n",
    "\n",
    "### OpenStreetMap Sample Project\n",
    "\n",
    "#### Map Area: Honolulu, Hawaii, United States\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing all necessary files\n",
    "import os\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "import string\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datadir = \"\"\n",
    "datafile = \"honolulu_hawaii.osm\"\n",
    "map_data = os.path.join(datadir, datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Problems Encountered in the Map(Auditing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 1612,\n",
      " 'nd': 288004,\n",
      " 'node': 242190,\n",
      " 'osm': 1,\n",
      " 'relation': 384,\n",
      " 'tag': 117607,\n",
      " 'way': 25500}\n"
     ]
    }
   ],
   "source": [
    "def count_tags(filename): ##iterative parsing using Element tree to process the map file and find out what tags are there\n",
    "        tags = {}\n",
    "        for event, elem in ET.iterparse(filename):\n",
    "            if elem.tag in tags: \n",
    "                tags[elem.tag] += 1\n",
    "            else:\n",
    "                tags[elem.tag] = 1\n",
    "        return tags\n",
    "map_tags = count_tags(map_data)\n",
    "pprint.pprint(map_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we founded that there are 242190 nodes, 117607 tags, 25500 ways and 384 relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#people invovlved in the map editing.\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        for e in element:\n",
    "            if 'uid' in e.attrib:\n",
    "                users.add(e.attrib['uid'])\n",
    "    return users\n",
    "users = process_map(map_data)\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 64324, 'lower_colon': 50719, 'other': 2564, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')                    # Regular Expressions for different cases matching\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "# initial expected street names\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\",\"Broadway\",\"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\",\n",
    "            \"Road\", \"Trail\", \"Parkway\"]\n",
    "\n",
    "def key_type(element, keys):                  #Finding counts for different tag categories\n",
    "    if element.tag == \"tag\":\n",
    "        for tag in element.iter('tag'):\n",
    "            k = tag.get('k')\n",
    "            if lower.search(k):\n",
    "                keys['lower'] += 1\n",
    "            elif lower_colon.search(k):\n",
    "                keys['lower_colon'] += 1\n",
    "            elif problemchars.search(k):\n",
    "                keys['problemchars'] += 1\n",
    "                print tag.get('k')\n",
    "            else:\n",
    "                keys['other'] += 1\n",
    "    return keys\n",
    "\n",
    "\n",
    "def process_map(filename):                      #Distributing in different categories and finding tag count\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}  \n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "map_keys = process_map(map_data)\n",
    "pprint.pprint(map_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    For the function: key_type & process_map. We check the \"k\" value for each \"\n",
    "\n",
    "    For the function 'key_type', we have a count of each of three tag categories in a dictionary: \"lower\", for tags that contain only lowercase letters and are valid, \"lower_colon\", for otherwise valid tags with a colon in their names, \"problemchars\", for tags with problematic characters, and\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auditing Problems associating with street name abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'106': set(['Pualei Cir, Apt 106']),\n",
      " 'Ave': set(['Kalakaua Ave']),\n",
      " 'Blvd': set(['Ala Moana Blvd']),\n",
      " 'Center': set(['Enchanted Lakes Shopping Center']),\n",
      " 'Circle': set(['Delay Circle', 'Papu Circle', 'Pualei Circle']),\n",
      " 'Dr': set(['Kipapa Dr']),\n",
      " 'Highway': set(['Farrington Highway',\n",
      "                 \"Kalaniana'ole Highway\",\n",
      "                 'Kalanianaole Highway',\n",
      "                 u'Kalaniana\\u2019ole Highway',\n",
      "                 'Kamehameha Highway',\n",
      "                 'Nimitz Highway',\n",
      "                 'Pali Highway']),\n",
      " 'Honolulu': set(['Moanalua, Honolulu']),\n",
      " 'Hwy': set(['Kamehameha Hwy']),\n",
      " 'Ike': set(['Ala Ike']),\n",
      " 'Kailua,': set(['Kaelepulu Dr, Kailua,']),\n",
      " 'King': set(['South King']),\n",
      " 'Loop': set(['98-402 Koauka Loop',\n",
      "              '98-410 Koauka Loop',\n",
      "              '98-500 Koauka Loop',\n",
      "              '98-501 Koauka Loop']),\n",
      " 'Mall': set(['Fort Street Mall', 'McCarthy Mall']),\n",
      " 'Momi': set(['Pali Momi']),\n",
      " 'Pkwy': set(['Meheula Pkwy']),\n",
      " 'St': set(['Ala Pumalu St', 'Lusitania St']),\n",
      " 'St.': set(['Lusitania St.']),\n",
      " 'Terrace': set(['Round Top Terrace']),\n",
      " 'Walk': set(['Beach Walk']),\n",
      " 'Way': set(['Ainakea Way',\n",
      "             'Coelho Way',\n",
      "             'Kuaaina Way',\n",
      "             'Pualani Way',\n",
      "             'Wai Nani Way']),\n",
      " 'highway': set(['kanehameha highway']),\n",
      " 'king': set(['king'])}\n"
     ]
    }
   ],
   "source": [
    "def audit_street_type(street_types, street_name):    # add unexpected street name to a list\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "            \n",
    "def is_street_name(elem):\n",
    "    # determine whether a element is a street name\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def audit_street(osmfile):\n",
    "    # iter through all street name tag under node or way and audit the street name value\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    return street_types\n",
    "\n",
    "st_types = audit_street(map_data)\n",
    "# print out unexpected street names\n",
    "pprint.pprint(dict(st_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping={  'Ave'  : 'Avenue',             #mapping abbreviations to their full form\n",
    "           'Ave.' : 'Avenue',\n",
    "           'Apt'  : 'Apartment',\n",
    "           'Blvd' : 'Boulevard',\n",
    "           'Dr'   : 'Drive',\n",
    "           'Ln'   : 'Lane',\n",
    "           'Pkwy' : 'Parkway',\n",
    "           'Rd'   : 'Road',\n",
    "           'Rd.'  : 'Road',\n",
    "           'St'   : 'Street',\n",
    "           'street' :\"Street\",\n",
    "           'Ct'   : \"Court\",\n",
    "           'Cir'  : \"Circle\",\n",
    "           'Cr'   : \"Court\",\n",
    "           'ave'  : 'Avenue',\n",
    "           'Hwg'  : 'Highway',\n",
    "           'Hwy'  : 'Highway',\n",
    "           'St.'  : 'Street',\n",
    "           'Sq'   : \"Square\",\n",
    "           '420'  : \"420\",\n",
    "           'Ext'  : \"Extension\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ala Ike => Ala Ike\n",
      "Lusitania St. => Lusitania Street\n",
      "Pualani Way => Pualani Way\n",
      "Wai Nani Way => Wai Nani Way\n",
      "Kuaaina Way => Kuaaina Way\n",
      "Ainakea Way => Ainakea Way\n",
      "Coelho Way => Coelho Way\n",
      "Papu Circle => Papu Circle\n",
      "Pualei Circle => Pualei Circle\n",
      "Delay Circle => Delay Circle\n",
      "Pali Highway => Pali Highway\n",
      "Farrington Highway => Farrington Highway\n",
      "Kamehameha Highway => Kamehameha Highway\n",
      "Kalaniana’ole Highway => Kalaniana’ole Highway\n",
      "Kalanianaole Highway => Kalanianaole Highway\n",
      "Kalaniana'ole Highway => Kalaniana'ole Highway\n",
      "Nimitz Highway => Nimitz Highway\n",
      "Pali Momi => Pali Momi\n",
      "Moanalua, Honolulu => Moanalua, Honolulu\n",
      "Kamehameha Hwy => Kamehameha Highway\n",
      "Kaelepulu Dr, Kailua, => Kaelepulu Dr, Kailua,\n",
      "Kipapa Dr => Kipapa Drive\n",
      "kanehameha highway => kanehameha highway\n",
      "South King => South King\n",
      "Enchanted Lakes Shopping Center => Enchanted Lakes Shopping Center\n",
      "Meheula Pkwy => Meheula Parkway\n",
      "Fort Street Mall => Fort Street Mall\n",
      "McCarthy Mall => McCarthy Mall\n",
      "Ala Pumalu St => Ala Pumalu Street\n",
      "Lusitania St => Lusitania Street\n",
      "Pualei Cir, Apt 106 => Pualei Cir, Apt 106\n",
      "98-501 Koauka Loop => 98-501 Koauka Loop\n",
      "98-500 Koauka Loop => 98-500 Koauka Loop\n",
      "98-402 Koauka Loop => 98-402 Koauka Loop\n",
      "98-410 Koauka Loop => 98-410 Koauka Loop\n",
      "king => king\n",
      "Beach Walk => Beach Walk\n",
      "Round Top Terrace => Round Top Terrace\n",
      "Ala Moana Blvd => Ala Moana Boulevard\n",
      "Kalakaua Ave => Kalakaua Avenue\n"
     ]
    }
   ],
   "source": [
    "def update_name(name, mapping, regex):                         #updating street names to correct form\n",
    "    m = regex.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type in mapping:\n",
    "            name = re.sub(regex, mapping[street_type], name)\n",
    "\n",
    "    return name\n",
    "\n",
    "for street_type, ways in st_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping, street_type_re)\n",
    "        print name, \"=>\", better_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems in zip codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'96': {'96712-9998',\n",
       "              '96734-9998',\n",
       "              '96815-2518',\n",
       "              '96815-2830',\n",
       "              '96815-2834',\n",
       "              '96817-1713',\n",
       "              '96825-9998',\n",
       "              '96826-4427'},\n",
       "             'HI': {'HI 96819'}})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict     # Auditing all zip codes in the given data\n",
    "\n",
    "def audit_zipcode(invalid_zipcodes, zipcode):\n",
    "    twoDigits = zipcode[0:2]\n",
    "    \n",
    "    if not zipcode.isdigit():\n",
    "        invalid_zipcodes[twoDigits].add(zipcode)\n",
    "    \n",
    "    elif twoDigits !=\"96\" :\n",
    "        invalid_zipcodes[twoDigits].add(zipcode) \n",
    "    elif len(zipcode)>5:\n",
    "        invalid_zipcodes[twoDigits].add(zipcode) \n",
    "        \n",
    "def is_zipcode(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def audit_zip(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    invalid_zipcodes = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_zipcode(tag):\n",
    "                    audit_zipcode(invalid_zipcodes,tag.attrib['v'])\n",
    "\n",
    "    return invalid_zipcodes\n",
    "\n",
    "map_zipcode = audit_zip(map_data)\n",
    "map_zipcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some zip codes contain hypen b/w them.\n",
    "\n",
    "One type of zip code contain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI 96819 => 96819\n",
      "96815-2518 => 96815\n",
      "96734-9998 => 96734\n",
      "96826-4427 => 96826\n",
      "96817-1713 => 96817\n",
      "96815-2830 => 96815\n",
      "96815-2834 => 96815\n",
      "96712-9998 => 96712\n",
      "96825-9998 => 96825\n"
     ]
    }
   ],
   "source": [
    "def update_zip(zipcode):                          # Fixing zip codes\n",
    "    testNum = re.findall('[a-zA-Z]*', zipcode)\n",
    "    if testNum:\n",
    "        testNum = testNum[0]\n",
    "    testNum.strip('-')\n",
    "    if testNum == \"HI\":\n",
    "        convertedZipcode = (re.findall(r'\\d+', zipcode))\n",
    "        if convertedZipcode:\n",
    "            if convertedZipcode.__len__() == 2:\n",
    "                return (re.findall(r'\\d+', zipcode))[0] + \"-\" +(re.findall(r'\\d+', zipcode))[1]\n",
    "            else:\n",
    "                return (re.findall(r'\\d+', zipcode))[0]\n",
    "    else:        \n",
    "        return (re.findall(r'\\d+', zipcode))[0]\n",
    "for street_type, ways in map_zipcode.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_zip(name)\n",
    "        print name, \"=>\", better_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip code errors were solved i.e removing hypen and text characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting data in required json Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]    #created field for json object\n",
    "# function that corrects incorrect street names\n",
    "def update_name(name, mapping):    \n",
    "    for key in mapping:\n",
    "        if key in name:\n",
    "            name = string.replace(name,key,mapping[key])\n",
    "    return name\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    node[\"created\"]={}\n",
    "    node[\"address\"]={}\n",
    "    node[\"pos\"]=[]\n",
    "    refs=[]\n",
    "    \n",
    "    # we only process the node and way tags\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        if \"id\" in element.attrib:\n",
    "            node[\"id\"]=element.attrib[\"id\"]\n",
    "        node[\"type\"]=element.tag\n",
    "\n",
    "        if \"visible\" in element.attrib.keys():\n",
    "            node[\"visible\"]=element.attrib[\"visible\"]\n",
    "      \n",
    "        # the key-value pairs with attributes in the CREATED list are added under key \"created\"\n",
    "        for elem in CREATED:\n",
    "            if elem in element.attrib:\n",
    "                node[\"created\"][elem]=element.attrib[elem]\n",
    "                \n",
    "        # attributes for latitude and longitude are added to a \"pos\" array\n",
    "        # include latitude value        \n",
    "        if \"lat\" in element.attrib:\n",
    "            node[\"pos\"].append(float(element.attrib[\"lat\"]))\n",
    "        # include longitude value    \n",
    "        if \"lon\" in element.attrib:\n",
    "            node[\"pos\"].append(float(element.attrib[\"lon\"]))\n",
    "\n",
    "        \n",
    "        for tag in element.iter(\"tag\"):\n",
    "            if not(problemchars.search(tag.attrib['k'])):\n",
    "                if tag.attrib['k'] == \"addr:housenumber\":\n",
    "                    node[\"address\"][\"housenumber\"]=tag.attrib['v']\n",
    "                    \n",
    "                if tag.attrib['k'] == \"addr:postcode\":\n",
    "                    node[\"address\"][\"postcode\"]=tag.attrib['v']\n",
    "                \n",
    "                # handling the street attribute, update incorrect names using the strategy developed before   \n",
    "                if tag.attrib['k'] == \"addr:street\":\n",
    "                    node[\"address\"][\"street\"]=tag.attrib['v']\n",
    "                    node[\"address\"][\"street\"] = update_name(node[\"address\"][\"street\"], mapping)\n",
    "\n",
    "                if tag.attrib['k'].find(\"addr\")==-1:\n",
    "                    node[tag.attrib['k']]=tag.attrib['v']\n",
    "                    \n",
    "        for nd in element.iter(\"nd\"):\n",
    "             refs.append(nd.attrib[\"ref\"])\n",
    "                \n",
    "        if node[\"address\"] =={}:\n",
    "            node.pop(\"address\", None)\n",
    "\n",
    "        if refs != []:\n",
    "           node[\"node_refs\"]=refs\n",
    "            \n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# process the xml openstreetmap file, write a json out file and return a list of dictionaries\n",
    "def process_map(file_in, pretty = False):\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process the file\n",
    "data = process_map(map_data, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing processed json data to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'client = MongoClient()      #importing json data to mongo db locally\\ndb = client.honolulu\\ncollection = db.honolulu\\ncollection.insert(data)'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''client = MongoClient()      #importing json data to mongo db locally\n",
    "db = client.honolulu\n",
    "collection = db.honolulu\n",
    "collection.insert(data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'honolulu'), u'honolulu')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection         #collection named honolulu for this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview with MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(cal_data)/1024/1024        #Size of xml file in MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(\"honolulu_hawaii.osm.json\")/1024/1024      #Size Of json file in MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267690"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.find().count()      #Total number of documents inside Mongo DB collection honolulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique users\n",
    "len(collection.group([\"created.uid\"], {}, {\"count\":0}, \"function(o, p){p.count++}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242159"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of nodes\n",
    "collection.find({\"type\":\"node\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25495"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of ways\n",
    "collection.find({\"type\":\"way\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': u'Tom_Holland', u'count': 102211},\n",
       " {u'_id': u'cbbaze', u'count': 14995},\n",
       " {u'_id': u'ikiya', u'count': 12807},\n",
       " {u'_id': u'kr4z33', u'count': 9470},\n",
       " {u'_id': u'Chris Lawrence', u'count': 9214}]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top five users with most contributions\n",
    "pipeline = [{\"$group\":{\"_id\": \"$created.user\",     \n",
    "                       \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"count\": -1}},\n",
    "            {\"$limit\": 5}]\n",
    "result = collection.aggregate(pipeline)\n",
    "x=list(result)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this shows that Tom_Holland is most active user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': u'Tom_Holland', u'proportion': 0.3818259927528111},\n",
       " {u'_id': u'cbbaze', u'proportion': 0.05601628749673129},\n",
       " {u'_id': u'ikiya', u'proportion': 0.04784265381598117},\n",
       " {u'_id': u'kr4z33', u'proportion': 0.03537674175352087},\n",
       " {u'_id': u'Chris Lawrence', u'proportion': 0.03442041167021555}]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Proportion of the top user contributions\n",
    "top_user_prop = [{\"$group\":{\"_id\": \"$created.user\",\n",
    "                       \"count\": {\"$sum\": 1}}},\n",
    "            {\"$project\": {\"proportion\": {\"$divide\" :[\"$count\",collection.find().count()]}}},\n",
    "            {\"$sort\": {\"proportion\": -1}},\n",
    "            {\"$limit\": 5}]\n",
    "result = list(collection.aggregate(top_user_prop))\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38% contribution was alone by Tom_Holland and others have very less compared to him."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Ideas and further exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': u'parking', u'count': 391},\n",
       " {u'_id': u'restaurant', u'count': 218},\n",
       " {u'_id': u'fast_food', u'count': 112},\n",
       " {u'_id': u'school', u'count': 85},\n",
       " {u'_id': u'toilets', u'count': 75},\n",
       " {u'_id': u'cafe', u'count': 64},\n",
       " {u'_id': u'place_of_worship', u'count': 38},\n",
       " {u'_id': u'library', u'count': 38},\n",
       " {u'_id': u'fire_station', u'count': 36},\n",
       " {u'_id': u'college', u'count': 29}]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Most common amenities in the area\n",
    "aminity=[{\"$match\":{\"amenity\":{\"$exists\":1}}},\n",
    "                              {\"$group\":{\"_id\":\"$amenity\",\"count\":{\"$sum\":1}}},\n",
    "                              {\"$sort\":{\"count\":-1}}, {\"$limit\":10}]\n",
    "result=list(collection.aggregate(aminity))\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most frequent amenities are parking, restaurant, fast_food respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': u'surface', u'count': 135},\n",
       " {u'_id': u'multi-storey', u'count': 54},\n",
       " {u'_id': u'underground', u'count': 3}]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Types of parking and their frequency \n",
    "pipeline = [{\"$match\":{\"amenity\":{\"$exists\":1}, \"amenity\":\"parking\", \"parking\":{\"$exists\":1}}}, \n",
    "            {\"$group\":{\"_id\":\"$parking\", \"count\":{\"$sum\":1}}},        \n",
    "            {\"$sort\":{\"count\":-1}}, \n",
    "            {\"$limit\":10}]\n",
    "result = list(collection.aggregate(pipeline))\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surface Parking is mostly performed so good road parking facilities in the area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': u'pizza', u'count': 8},\n",
       " {u'_id': u'japanese', u'count': 7},\n",
       " {u'_id': u'regional', u'count': 6},\n",
       " {u'_id': u'chinese', u'count': 5},\n",
       " {u'_id': u'american', u'count': 5},\n",
       " {u'_id': u'international', u'count': 4},\n",
       " {u'_id': u'thai', u'count': 4},\n",
       " {u'_id': u'italian', u'count': 3},\n",
       " {u'_id': u'asian', u'count': 3},\n",
       " {u'_id': u'indian', u'count': 2}]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cuisines in restaurants\n",
    "pipeline = [{\"$match\":{\"amenity\":{\"$exists\":1}, \"amenity\":\"restaurant\", \"cuisine\":{\"$exists\":1}}}, \n",
    "            {\"$group\":{\"_id\":\"$cuisine\", \"count\":{\"$sum\":1}}},        \n",
    "            {\"$sort\":{\"count\":-1}}, \n",
    "            {\"$limit\":10}]\n",
    "result = list(collection.aggregate(pipeline))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': u'burger', u'count': 18},\n",
       " {u'_id': u'sandwich', u'count': 5},\n",
       " {u'_id': u'mexican', u'count': 4},\n",
       " {u'_id': u'pizza', u'count': 3},\n",
       " {u'_id': u'sushi', u'count': 3},\n",
       " {u'_id': u'ice_cream', u'count': 1},\n",
       " {u'_id': u'asian', u'count': 1},\n",
       " {u'_id': u'american', u'count': 1},\n",
       " {u'_id': u'hawaiian', u'count': 1},\n",
       " {u'_id': u'regional', u'count': 1}]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cuisines in fast_food\n",
    "pipeline = [{\"$match\":{\"amenity\":{\"$exists\":1}, \"amenity\":\"fast_food\", \"cuisine\":{\"$exists\":1}}}, \n",
    "            {\"$group\":{\"_id\":\"$cuisine\", \"count\":{\"$sum\":1}}},        \n",
    "            {\"$sort\":{\"count\":-1}}, \n",
    "            {\"$limit\":10}]\n",
    "result = list(collection.aggregate(pipeline))\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "burger is most popular cuisine in fast_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': u\"Kawaiaha'o Church School\", u'count': 1},\n",
       " {u'_id': u'The Kamehameha Schools', u'count': 1},\n",
       " {u'_id': u'Noelani School', u'count': 1},\n",
       " {u'_id': u\"Ka'elepulu Elementary\", u'count': 1},\n",
       " {u'_id': u'Hawaii School for the Deaf and the Blind', u'count': 1},\n",
       " {u'_id': u'Mililani Ike Elementary School', u'count': 1},\n",
       " {u'_id': u'R. L. Stevenson Middle School', u'count': 1},\n",
       " {u'_id': u'Shade House', u'count': 1},\n",
       " {u'_id': u'Highlands Intermediate School', u'count': 1},\n",
       " {u'_id': u'Mid-Pacific Institute', u'count': 1}]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#name of different schools\n",
    "pipeline = [{\"$match\":{\"amenity\":{\"$exists\":1}, \"amenity\": \"school\", \"name\":{\"$exists\":1}}},\n",
    "            {\"$group\":{\"_id\":\"$name\", \"count\":{\"$sum\":1}}},\n",
    "            {\"$sort\":{\"count\":-1}},{\"$limit\":10}]\n",
    "result = list(collection.aggregate(pipeline))\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only single branch of every school in this city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': u'residential', u'count': 6832},\n",
       " {u'_id': u'service', u'count': 4538},\n",
       " {u'_id': u'living_street', u'count': 1759},\n",
       " {u'_id': u'turning_circle', u'count': 1354},\n",
       " {u'_id': u'footway', u'count': 555}]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# types of roads or highways\n",
    "pipeline = [{'$match': {'highway': { '$exists': 1}}}, \n",
    "        {'$group': {'_id': '$highway',\n",
    "                    'count': {'$sum': 1}}}, \n",
    "        {'$sort': {'count': -1}},\n",
    "        {'$limit': 5}]\n",
    "result=list(collection.aggregate(pipeline)) \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So mostly residential area is there in the city which highway covers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': u'christian', u'count': 22},\n",
       " {u'_id': None, u'count': 9},\n",
       " {u'_id': u'buddhist', u'count': 6},\n",
       " {u'_id': u'muslim', u'count': 1}]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# types of religion followed\n",
    "pipeline = [{\"$match\":{\"amenity\":{\"$exists\":1}, \"amenity\":\"place_of_worship\"}},\n",
    "                      {\"$group\":{\"_id\":\"$religion\", \"count\":{\"$sum\":1}}},\n",
    "                      {\"$sort\":{\"count\":-1}}]\n",
    "result=list(collection.aggregate(pipeline)) \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So mostly Christian religion is followed ...\n",
    "\n",
    "### Additional Idea\n",
    "\n",
    "For improving the database some validations should be applied while filling the information in specific way.\n",
    "\n",
    "And also user who contributed most should be displayed on the website so that others also try to contribute more by getting motivation from his/her work.\n",
    "\n",
    ">From above two ideas firstly data is entered in more proper format.\n",
    "Secondly contribution increases if you give some credit to persons who contributed more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Data Wrangling on Honolulu, Hawai, USA openstreet data of size greater than 50 MB I found that:\n",
    "\n",
    "464 people were involved in its map editing out of which 1 contributed the most around 38%.\n",
    "\n",
    "Some errors in street name abbreviations and zip codes were found while auditing the dataset which were fixed by mapping.\n",
    "\n",
    "Parking is most frequent amenity in the area and in parking surface parking is most common.\n",
    "\n",
    "People there are fond of pizzas and burgers and other fast food items. \n",
    "\n",
    "Mostly Christians are there in that area.\n",
    "\n",
    "So data must have lots of other hidden information as any type of tag is allowed and could be more further explored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.google.com/document/d/1F0Vs14oNEs2idFJR3C_OPxwS6L0HPliOii-QpbmrMo4/pub#h.ueey7dly83g7\n",
    "\n",
    "https://mapzen.com/data/metro-extracts/metro/honolulu_hawaii/\n",
    "\n",
    "Case study of lectures\n",
    "\n",
    "http://wiki.openstreetmap.org/wiki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
